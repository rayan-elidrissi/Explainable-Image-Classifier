# Explainable Image Classifier
Beyond model performance, image classifier that explains its decisions using interpretability techniques like Grad-CAM or LIME.

![Alt text](docs/image_classifier.png)

## Features
- A Convolutional Neural Network (CNN) model trained to classify images into different categories.
- Utilizes Grad-CAM (Gradient-weighted Class Activation Mapping) or LIME (Local Interpretable Model-agnostic Explanations) to visually explain the model's decision-making process.
- Includes a module to generate adversarial examples, testing the robustness of the model against adversarial attacks.
- Demonstrates how slight modifications to input images can change the model's prediction, providing insights into the decision boundaries of the classifier.

## Installation
```

```

## Usage
```

```

## Contributing
Contributions are welcome! Feel free to open an issue or submit a pull request.
